{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mDwNAZEY9Xgr"
      },
      "source": [
        "Fashion-MNIST is a dataset of Zalando's article images consisting of a training set of 60,000 examples and a test set of 10,000 examples. Each example is a 28x28 grayscale image, associated with a label from 10 classes.\n",
        "\n",
        "Each training and test example is assigned to one of the following labels:\n",
        "\n",
        "Label\tDescription\n",
        "0\tT-shirt/top\n",
        "1\tTrouser\n",
        "2\tPullover\n",
        "3\tDress\n",
        "4\tCoat\n",
        "5\tSandal\n",
        "6\tShirt\n",
        "7\tSneaker\n",
        "8\tBag\n",
        "9\tAnkle boot\n",
        "\n",
        "Class counts are all 1,000:\n",
        "{0: 1000, 1: 1000, 2: 1000, 3: 1000, 4: 1000, 5: 1000, 6: 1000, 7: 1000, 8: 1000, 9: 1000}\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m9hmDV_k1elA"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "import tensorflow_datasets as tfds\n",
        "\n",
        "# You cannot modify from here until it is indicated by a comment\n",
        "(test_data),test_data_info=tfds.load('fashion_mnist',split='test',with_info=True,as_supervised=True)\n",
        "\n",
        "(train_data),ds_info=tfds.load('fashion_mnist',split=['train[3000:57000]'],with_info=True,as_supervised=True)\n",
        "\n",
        "\n",
        "\n",
        "def getnewtst():\n",
        "  (new_test),new_test_info=tfds.load('fashion_mnist',split=['train[0:2999]'],with_info=True,as_supervised=True)\n",
        "  new_test = new_test[0].map(normalize_img, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "  new_test = new_test.batch(64)\n",
        "  new_test = new_test.cache()\n",
        "  new_test = new_test.prefetch(tf.data.AUTOTUNE)\n",
        "  return new_test\n",
        "\n",
        "\n",
        "# Can modify code now below this comment Though be careful if you change the\n",
        "# normalization\n",
        "\n",
        "def normalize_img(image, label):\n",
        "  \"\"\"Normalizes images: `uint8` -> `float32`.\n",
        "  The model wants the float and tfds gives you 0-255.\"\"\"\n",
        "  return tf.cast(image, tf.float32) / 255., label\n",
        "\n",
        "\n",
        "# The steps below or a variation are required to actually extract the images\n",
        "# and labels for use in training/testing\n",
        "\n",
        "train_data = train_data[0].map(normalize_img, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "train_data = train_data.cache()\n",
        "train_data = train_data.shuffle(ds_info.splits['train'].num_examples)\n",
        "train_data = train_data.batch(64)\n",
        "train_data = train_data.prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "\n",
        "test_data = test_data.map(normalize_img, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "test_data = test_data.batch(128)\n",
        "test_data = test_data.cache()\n",
        "test_data = test_data.prefetch(tf.data.AUTOTUNE)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LcNXigc06Am4"
      },
      "outputs": [],
      "source": [
        "model = tf.keras.models.Sequential([\n",
        "  tf.keras.layers.Conv2D(32, kernel_size=(3, 3),\n",
        "                 activation='relu'\n",
        "                 ),\n",
        "tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
        "tf.keras.layers.Flatten(),\n",
        "  tf.keras.layers.Dense(64, activation='relu'),\n",
        "  tf.keras.layers.Dense(10, activation='softmax')\n",
        "])\n",
        "model.compile(\n",
        "    optimizer=tf.keras.optimizers.SGD(momentum=0.3),\n",
        "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "    metrics=[tf.keras.metrics.SparseCategoricalAccuracy()],\n",
        ")\n",
        "\n",
        "model.fit(\n",
        "    train_data,\n",
        "    epochs=3,\n",
        "    validation_data=getnewtst(),\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "# This code checks the count per class and each training has 60K\n",
        "# Each class in test also has 1K for a total of 10K\n",
        "def checkclasscnt(name,mysplit):\n",
        "  ds,ds_info = tfds.load(name,split=mysplit,with_info=True)\n",
        "  print(ds_info.features[\"label\"].names)\n",
        "# Get the number of classes\n",
        "  num_classes = ds_info.features['label'].num_classes\n",
        "\n",
        "# Create a dictionary to store class counts\n",
        "  class_counts = {i: 0 for i in range(num_classes)}\n",
        "\n",
        "\n",
        "  for example in ds:  # example is `{'image': tf.Tensor, 'label': tf.Tensor}`\n",
        "\n",
        "   label = example[\"label\"]\n",
        "   class_counts[label.numpy()] += 1\n",
        "  return(class_counts)\n",
        "\n",
        "\n",
        "ccount=checkclasscnt('fashion_mnist','train')\n",
        "print(ccount)\n",
        "'''"
      ],
      "metadata": {
        "id": "QhA40kwk-eXp"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}